---
title: 人工智能基础
tags:
  - 线性回归
  - 梯度下降
  - 最大似然估计
  - 最大后验估计
categories: 人工智能
mathjax: true
abbrlink: a1bded03
date: 2025-10-24 16:44:58
---

## 核心思想

基于已知数据构造概率模型，反过来再运用概率模型对未知数据进行预测与分析。

### 频率学派与统计学习

频率学派所说的概率表示的是 **事件发生频率的极限值**，在无限次独立重复实验下才准确。

> 频率统计理论的核心在于认定待估计的参数是固定不变的常量（比如硬币出现正面的概率），讨论参数的概率分布是没有意义的；而用来估计参数的数据是随机的变量（比如某次实验正面还是反面），每个数据都是参数支配下一次独立重复试验的结果。由于参数本身是确定的，那频率的波动就并非来源于参数本身的不确定性，而是由有限次观察造成的干扰而导致。

有限次的实验得到的数据是关于参数的不完全信息，所以从样本估计整体必然产生误差。

极大似然估计：在参数固定的前提下，使数据出现的条件概率最大化。

### 统计机器学习

> 参数确定，数据随机

通过对给定的指标优化（比如极大似然函数），估计模型中参数的取值，和参数有关的信息全来自数据。受噪声的影响，观测数据并不是未知参数的准确反映，损失函数定义了模型性能的度量方式，其期望称为风险，风险最小化是参数估计的准则。

### 贝叶斯学派

概率表示的是客观上 **事件的可信程度**。
$$
P(H|D) = \dfrac{P(D|H)\cdot P(H)}{P(D)}
$$
其中 $P(H)$ 是先验概率，$P(D|H)$ 是似然概率，$P(H|D)$ 是后验概率。相对于频率主义的最大似然估计，贝叶斯主义在参数估计中使后验概率最大化，使用最大后验概率估计。

## 梯度下降公式的推导

目标是最小化一个可微函数 $f(\boldsymbol{\theta}), \theta \in \mathbb{R}$。

函数 $f(\theta)$ 在 $\theta_0$ 附近的泰勒展开式为

$$
f(\theta) = f(\theta_0) + \dfrac{f'(\theta_0)}{1!}(\theta - \theta_0) + \cdots
$$

函数 $f(\theta  + \Delta \theta)$ 在 $\theta$ 附近的泰勒展开式为

$$
f(\theta  + \Delta \theta) = f(\theta) + \dfrac{f'(\theta)}{1!}(\Delta \theta) + \cdots
$$

保留一阶泰勒展开，得到

$$
f(\boldsymbol{\theta} + \Delta \boldsymbol{\theta}) = f(\boldsymbol{\theta}) + \nabla f(\boldsymbol{\theta})^{\top}\Delta \boldsymbol{\theta}
$$

其中 $\Delta \boldsymbol{\theta}$ 是要移动的方向，为了使得 $f(\boldsymbol{\theta} + \Delta \boldsymbol{\theta}) < f(\boldsymbol{\theta})$，需要满足

$$
\nabla f(\boldsymbol{\theta})^{\top}\Delta \boldsymbol{\theta} < 0\\
$$

表示移动方向与梯度方向相反，自然选择

$$
\Delta \boldsymbol{\theta} = -\eta\cdot \nabla f(\boldsymbol{\theta})\\
$$

其中 $\eta > 0$。则参数更新规则为

$$
\theta_{t+1} = \theta_t - \eta\cdot \nabla f(\boldsymbol{\theta})
$$

---

以回归模型为例，用 $x$ 的线性函数近似 $y$，

$$
h_{\theta}(x) = \sum_{i = 1}^n \theta_i x_i = \boldsymbol{\theta}^{\top}\mathbf{x}, \space x_0 = 1
$$

其代价函数为

$$
J(\theta) = \dfrac{1}{2}\sum_{i = 1}^n{ h_{\theta}(x^{(i)} - y^{(i)})^2 }
$$

偏导数计算如下

$$
\begin{aligned}
\dfrac{\partial}{\partial \theta_j} J(\theta)
&= \dfrac{\partial}{\partial \theta_j} \dfrac{1}{2}( h_{\theta}(x) - y )^2\\
&= ( h_{\theta}(x) - y ) \cdot \dfrac{\partial}{\partial \theta_j}( h_{\theta}(x) - y )\\
&= ( h_{\theta}(x) - y ) \cdot \dfrac{\partial}{\partial \theta_j}( \sum_{i = 1}^n \theta_i x_i - y )\\
&= ( h_{\theta}(x) - y ) x_j\\
\end{aligned}
$$

则更新规则为

$$
\theta := \theta - \eta \sum_{i = 1}^n ( h_{\theta}(x^{(i)}) - y^{(i)} ) x^{(i)}\\
$$

这种方法需要再执行单次更新前扫描整个训练集，被称为 [**批量梯度下降**](https://github.com/Euler0525/AI-learning/blob/master/Optimization/03-bgd.ipynb)。

## 线性回归

设模型的预测值为 $f(x_k) = \theta^{\top}x_k$，观测值为 $ y_k $，则噪声 $ \varepsilon_k = y_k - f(x_k) $。噪声服从参数为 $(0, \sigma^2)$ 的正态分布，即 $\varepsilon_k\sim N(0, \sigma^2)$，其概率密度函数为

$$
p(\varepsilon_k) = \dfrac{1}{\sqrt{2\pi}\sigma}\exp{(-\frac{\varepsilon_k^2}{2\sigma^2})}
$$

**单个样本 $ (x_k, y_k) $ 出现的概率等价于噪声取值为 $\varepsilon_k=y_k-f(x_k)$ 的概率**，将 $\varepsilon_k=y_k-\theta^{\top}x_k$ 带入噪声的概率密度函数得到单个样本的概率密度

$$
p(y_k|x_k; \theta) = \dfrac{1}{\sqrt{2\pi}\sigma}\exp{\left(-\frac{(y_k-\theta^{\top}x_k)^2}{2\sigma^2}\right)}
$$

其中 $p(y_k|x_k;\theta)$ 表示给定 $ x_k $ 和参数 $ \theta $ 的条件下，观测到 $ y_k $ 的概率密度，核心是模型参数 $ \theta $ 的函数。

若有 $ N $ 个样本 $\{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}$，各个样本之间相互独立，则所有样本同时出现的概率为

$$
\begin{aligned}
L(\theta) &= \prod_{k = 1}^N p(y_k|x_k; \theta) = \prod_{k = 1}^N \dfrac{1}{\sqrt{2\pi}\sigma}\exp{\left(-\frac{(y_k-\theta^{\top}x_k)^2}{2\sigma^2}\right)}\\
\ln L(\theta) &= -\dfrac{N}{2}\ln(2\pi) - N\ln \sigma -\frac{1}{2\sigma^2}\sum_{k = 1}^N{(y_k-\theta^{\top}x_k)^2}
\end{aligned}
$$

于是，最大化似然函数 $ L(\theta) $ 等价于最小化 $\displaystyle\sum_{k=1}^N{(y_k-\theta^{\top}x_k)^2}$，即最小二乘法的损失函数，同时也证明了在噪声满足正态分布的条件下，最小二乘与最大似然等价。

对于单变量的线性回归，$y=\theta_1x + \theta_0$，带入到均方误差的表达式中对 $ \theta_1 $ 和 $\theta_0$ 求偏导， 极值点即为线性回归的最优解

$$
\begin{aligned}
\theta_1 &= \dfrac{\displaystyle\sum_{k = 1}^{N}y_k(x_k - \displaystyle\frac{1}{N}\sum_{k = 1}^N x_k)}{\displaystyle\sum_{k = 1}^N x_k^2 - \frac{1}{N}(\displaystyle\sum_{k = 1}^N x_k)^2}\\
\theta_0 &= \dfrac{1}{N} \sum_{k = 1}^N (y_k - \theta_1 x_k)\\
\end{aligned}
$$

对于多变量的线性回归，$\displaystyle\sum_{k=1}^N{(y_k-\theta^{\top}x_k)^2} = \displaystyle\sum_{k=1}^N{(y_k-\theta^{\top}x_k)^{\top}(y_k-\theta^{\top}x_k)} = (\mathbf{y} - \mathbf{X}\mathbf{\theta})^{\top}(\mathbf{y} - \mathbf{X}\mathbf{\theta})$。

定义损失函数为

$$
\begin{aligned}
L &= (\mathbf{y} - \mathbf{X}\mathbf{\theta})^{\top}(\mathbf{y} - \mathbf{X}\mathbf{\theta})\\
&= \mathbf{y}^{\top}\mathbf{y} - 2\mathbf{\theta}^{\top}\mathbf{X}^{\top}\mathbf{y} + \mathbf{\theta}^T(\mathbf{X}^{\top}\mathbf{X})\mathbf{\theta}\\
\end{aligned}
$$

令 $\dfrac{\partial{L}}{\partial \mathbf{\theta}} = -  2\mathbf{X}^{\top}\mathbf{y} + 2\mathbf{X}^{\top}\mathbf{X}\mathbf{\theta} = 0$，在 $\mathbf{X}^{\top}\mathbf{X}$ 的逆矩阵存在的前提下，得到参数的最优解为

$$
\mathbf{\theta} = (\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}\mathbf{y}
$$

## 泛化和正则

### 泛化

#### 偏差-方差均衡

训练集输入 $x^{(i)}$ 是随机选择的，输出 $y^{(i)}=h^*(x^{(i)}) + \xi^{(i)}$ 生成，其中 $\xi^{(i)}\sim \mathcal{N}(0,\sigma^2)$ 表示观测噪声。测试样本 $(x,y)$ 也有相同的输入-输出映射 $y=h^*(x)+\xi$，其中 $\xi\sim \mathcal{N}(0,\sigma^2)$，本质上，我们的目标是恢复函数 $h^*(\cdot)$.

> 将模型的 **偏差(bias)** 定义为即使拟合到无限大的训练数据集，曾存在的测试误差。在这种情况下，表现为欠拟合。
>
> 训练集中的虚假信息大部分是由于观测噪声 $\xi^{(i)}$ 引起的，拟合这些虚假信息会导致模型具有较大的测试误差，将其定义为模型的方差。
>
> 通常，偏差和方差之间存在权衡。如果模型过于简单且参数很少，那么它可能具有较大的偏差（但方差较小），并且通常会遭受欠拟合；如果它过于复杂且参数很多，那么它可能遭受较大的方差（但偏差较小），因此会过拟合。

- 对于回归问题的数学分解——偏差-方差权衡

抽取一个训练集 $S = \{ x^{(i)}, y^{(i)} \}^n_{i=1}$，其中 $y^{(i)} = h^*(x^{(i)}) + \xi^{(i)}, \xi^{(i)}\sim \mathcal{N}(0,\sigma^2)$，在该数据集上训练一个模型记为 $\hat{h}_S$，取测试样本 $(x,y)$，使得 $y=h^*(x) + \xi, \xi\sim \mathcal{N}(0,\sigma^2)$，并测量测试误差的期望

$$
\mathrm{MSE}(x) = \mathbb{E}_{S,\xi}[(y-\hat{h}_S(x))^2]
$$

下面将 $\mathrm{MSE}$ 分解，

$$
\begin{aligned}
\mathrm{MSE}(x) &= \mathbb{E}_{S,\xi}[(y-\hat{h}_S(x))^2]\\
&= \mathbb{E}_{S,\xi}[(h^*(x) + \xi - \hat{h}_S(x))^2]\\
&= \mathbb{E}_{S,\xi}[(\xi + (h^*(x) - \hat{h}_S(x)))^2]\\
&= \mathbb{E}[\xi^2] + \mathbb{E}[(h^*(x) - \hat{h}_S(x))^2]\\
&= \sigma^2 + \mathbb{E}[(h^*(x) - \hat{h}_S(x))^2]\\
\end{aligned}
$$

抽取无限多个数据集作为训练集，对他们在 $x$ 上的预测进行平均而获得的模型定义 $h_{avg}(x) = \mathbb{E}_S[\hat{h}_S(x)]$。进一步分解 $\mathrm{MSE}$，

$$
\begin{aligned}
\mathrm{MSE}(x)
&= \sigma^2 + \mathbb{E}[(h^*(x) - \hat{h}_S(x))^2]\\
&= \sigma^2 + \mathbb{E}[(h^*(x) - h_{avg}(x) + h_{avg}(x) - \hat{h}_S(x))^2]\\
&= \sigma^2 + \underbrace{[(h^*(x) - h_{avg}(x)]^2}_{Bias^2} + \underbrace{\mathrm{Var}[{\hat{h}_S(x)}}_{Variance}]\\
\end{aligned}
$$

如前所述，偏差本质上是由于模型族本身无法很好地近似 $h^*$，而不是由于数据不足引起的；方差表征的是有限数据集的随机性如何引入学习模型中的误差，衡量了学习模型对数据集中随机性的敏感度，随着数据集增大，方差通常减小。

<img src="https://cdn.jsdelivr.net/gh/Euler0525/tube@master/ai/bias_var_tradeoff.webp" width="60%" />

---

#### 传统偏差-方差权衡的扩展

- 模型层面

当模型复杂度逐渐增大时，训练误差持续下降，而测试误差先下降后上升，形成传统的 U 形曲线。当模型继续变大到 **恰好能将训练数据完全拟合** 之上时，测试误差再次下降，形成第二次下降，于是整体呈现 **双下降** 形状。

<img src="https://cdn.jsdelivr.net/gh/Euler0525/tube@master/ai/double_dec_model.webp" alt="double_dec_model" width="80%" />

- 样本层面

随着样本数量的增加，测试误差并非单调递减。而是测试误差先下降，然后在样本数量与参数数量接近时增加并达到峰值，然后再次下降。

<img src="https://cdn.jsdelivr.net/gh/Euler0525/tube@master/ai/double_dec_sample.webp" alt="double_dec_sample" width="80%" />

> 因此，多数的训练算法在样本数量接近参数数量时，没有达到最优结果。例如在使用梯度下降优化器时，算法可能找到拟合数据的任意解，导致泛化误差增大。
>
> 缓解策略包括：调整正则化参数；避免以参数数量作为复杂度度量；

### 正则

在训练损失函数中添加一个附加项

$$
\mathcal{J}_{\lambda}(\theta) = \mathcal{J}(\theta) + \lambda R(\theta), \space \lambda \geq 0
$$

正则项 $R(\theta)$ 用于衡量模型 $ \theta $ 的复杂程度。

**目标是既能以很小的损失拟合数据，又能有较小的模型复杂度。**

以 $\mathscr{l}_2$ 正则化作为正则项为例，$R(\theta) = \dfrac{1}{2}||\theta||^2$，在进行梯度下降时，等价于将 $ \theta $ 乘以一个标量因子 $1-\eta\lambda$

$$
\begin{aligned}
\theta &\leftarrow \theta - \eta \nabla \mathcal{J}_{\lambda}(\theta)\\
&= \theta - \eta \nabla \mathcal{J}(\theta) - \eta\lambda \theta\\
&= \underbrace{(1 - \eta\lambda)}_{权重衰减}\theta - \eta \nabla \mathcal{J}(\theta)\\
\end{aligned}
$$

### 交叉验证

假设有一些有限的模型集合 $\mathcal{M} = \{M_1, M_2,\cdots\}$

通过 **留出交叉验证** 选择模型，给定一个训练集 $S$，

1. 随机将 $S$ 分割成 $S_{train}$ 和 $S_{cv}$，分别为训练集和留出交叉验证集；
2. 仅在 $S_{train}$ 上训练每个模型 $M_i$，得到一些假设 $h_i$；
3. 选择在留出交叉验证集上误差 $\hat{\varepsilon}_{S_{cv}}(h_i)$ 最小的假设 $h$，

通常，交叉验证集占数据量的 $\dfrac{1}{4}\sim\dfrac{1}{3}$，例如 $30\%$。

$k$ 折交叉验证

1. 随机将 $S$ 分割成 $k$ 个不相交的自己，每个子集包含 $\dfrac{m}{k}$ 个训练样本，分别为 $S_1,S_2,\cdots,S_k$；
2. 对于每个模型，对于 $j=1,2,\cdots ,k$，在 $S_1\cup \cdots \cup S_{j-1}\cup S_{j+1}\cup S_k$ 上训练每个模型 $M_i$，得到一些假设 $h_{ij}$，在 $S_j$ 上测试假设 $h_{ij}$，得到验证误差 $\hat{\varepsilon}_{S_j}(h_{ij})$，
3. 模型 $M_i$ 的泛化误差计算为 $\hat{\varepsilon}_{S_j}(h_{ij})$ 对 $j$ 的平均值；
4. 选择泛化误差最小的模型，并在整个训练集 $S$ 上训练该模型，得到最终的输出 $h$

### 贝叶斯与正则化

前文的参数拟合使用的是最大似然估计，将 $\theta$ 视为未知的常数

$$
\theta_{MLE} = \arg \max_{\theta} \prod_{i = 1}^n p(y^{(i)}|x^{(i)};\theta)
$$

另一种方法是贝叶斯方法，将参数 $\theta$ 视为随机变量，先验知识为 $p(\theta)$，其后验分布为

$$
\begin{aligned}
p(\theta|S) &= \dfrac{p(S|\theta)p(\theta)}{p(S)}\\
&= \dfrac{ \left( \prod_{i = 1}^n p(y^{(i)}|x^{(i)};\theta) \right) p(\theta)}{ \int_{\theta}\left( \prod_{i = 1}^n p(y^{(i)}|x^{(i)};\theta) \right) p(\theta)\mathrm{d}\theta  }
\end{aligned}
$$

其中 $p(y^{(i)}|x^{(i)};\theta)$ 由模型决定，以贝叶斯逻辑回归为例

$$
p(y^{(i)}|x^{(i)};\theta) = h_{\theta}(x^{(i)})^{y^{(i)}}(1-h_{\theta}(x^{(i)}))^{1- y^{(i)}}, \space h_{\theta}(x^{(i)}) = \dfrac{1}{1 + e^{-\theta^{\top}x^{(i)}}}
$$

当给定一个新的测试样本 $x$ 并对其预测时，

$$
p(y|x, S) = \int_{\theta} p(\theta|S) p(y|x, \theta)\mathrm{d}\theta\\
$$

> 计算后验分布需要对 $\theta$ 积分，无法得到闭式解。实际使用时，采用近似方法（单点估计）

## 参考资料

[人工智能基础课](https://time.geekbang.org/column/intro/100003101?tab=catalog)

[cycleuser/Stanford-CS-229](https://github.com/cycleuser/Stanford-CS-229)

[Bias–variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)

[Bias-Variance Trade Off - Machine Learning](https://www.geeksforgeeks.org/machine-learning/ml-bias-variance-trade-off/)
