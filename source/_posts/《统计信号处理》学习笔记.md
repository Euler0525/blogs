---
title: 《统计信号处理》学习笔记
tags:
  - 统计信号处理
categories: 信号处理
mathjax: true
abbrlink: 9d011f47
date: 2026-01-08 10:34:50
---

## 数学基础

用概率密度函数（Probability Density Function, PDF）描述一组随机数据，即 $p(x_0, x_1, \cdots, x_{n-1};\theta)$，PDF 以未知量 $\theta$ 为参数，以 $n=1$，$\theta$ 表示均值为例，数据的 PDF 为

$$
p(x_0;\theta) = \dfrac{1}{\sqrt{2\pi\sigma^2}} \exp{\left( -\dfrac{(x_0-\theta)^2}{2\sigma^2} \right)}
$$

然后就可以根据 $x_0$ 的观测值推断 $\theta$ 的值。

### 估计量性能评估

将数据建模为

$$
x_n = A + w_n
$$

其中 $w_n$ 为加性高斯白噪声（Additive Gaussian White Noise, AWGN），即 $w_i\sim \mathcal{N}(0, \sigma^2)$ 表示均值为 $0$，方差为 $\sigma^2$ 的高斯分布，并且所有样本是互不相关的。利用下式即数据的样本均值估计 $A$

$$
\hat{A} = \dfrac{1}{N} \sum_{n = 0}^{N-1} x_n
$$

满足

$$
\begin{aligned}
E(\hat{A}) &= E\left(\dfrac{1}{N} \sum_{n = 0}^{N-1} x_n\right) = \dfrac{1}{N}\sum_{n = 0}^{N-1}(x_n) = A\\
\mathrm{var} (\hat{A}) &= \mathrm{var} \left(\dfrac{1}{N} \sum_{n = 0}^{N-1} x_n\right) = \dfrac{1}{N^2}\sum_{n = 0}^{N-1}\mathrm{var}(x_n) = \dfrac{1}{N^2} N\sigma^2 = \dfrac{\sigma^2}{N}\\
\end{aligned}
$$

## 最小方差无偏估计

### 无偏估计量

无偏估计意味着估计量的平均值为未知参数 $\theta$ 的真值，如果

$$
E(\hat{\theta}) = \theta\qquad a < \theta < b
$$

说明估计量是无偏的，其中 $(a, b)$ 表示 $\theta$ 可能的取值范围。

对于同一个参数有多个估计可用的情况，即 $\{\hat{\theta}_0, \hat{\theta}_1, \cdots, \hat{\theta}_{n-1}\}$，对这些组合求平均，即

$$
\hat{\theta} = \dfrac{1}{n}\sum_{i = 0}^{n-1} \hat{\theta}_i
$$

假设每个估计量都是无偏的，方差相同且互不相关，则

$$
E(\hat{\theta}) = \theta, \mathrm{var}(\hat{\theta}) = \dfrac{\mathrm{var}(\hat{\theta}_0)}{n}
$$

因此，求平均的估计值越多，方差越小，当 $n \to \infty$ 时，$\hat{\theta}\to \theta$。

### 最小方差准则

均方误差定义为

$$
\mathrm{mse}(\hat{\theta}) = E [(\hat{\theta} - \theta)^2]
$$

衡量估计值偏离真值的平方偏差的统计平均值。

$$
\begin{aligned}
\mathrm{mse}(\hat{\theta}) &= E [(\hat{\theta} - \theta)^2]\\
&= E\left\{ \left [ \left(\hat{\theta} - E(\hat{\theta}) \right) + \left( E(\hat{\theta}) - \theta \right) \right]^2 \right\}\\
\end{aligned}
$$

其中第一部分是估计量围绕其数学期望的随机波动，第二部分是估计量的期望围绕真值的波动，展开后得到

$$
\mathrm{mse}{(\hat{\theta})} = \mathrm{var}(\hat{\theta}) + b^2(\theta)\\
$$

其中 $b(\theta) = E(\hat{\theta}) - \theta$，表示估计量的偏差。上式表明 $MSE$ 是由 **估计量的方差** 和 **偏差** 引起的误差组成的。

对于有偏的估计量，$MSE$ 与参数 $\theta$ 的真值有关，最小化 $MSE$ 可能导致不可实现的估计量，如果约束估计量为无偏的，然后最小化方差，得到的估计量就是最小方差无偏（Minimum Variance Unbiased, MVU）估计量。

### 最小方差无偏估计的存在性

> 不总是存在一个估计量 $\hat{\theta}$，对于所有的 $\theta$，其方差都小于其它无偏估计量！

## Cramer-Rao 下限

观测到单个样本

$$
x_0 = A + w_0, \quad w_0\sim \mathcal{N}(0, \sigma^2)\\
$$

无偏估计满足 $\hat{A}=x_0, \mathrm{var}(\hat{A})= \sigma^2$.

考虑 PDF 的自然对数

$$
\ln p(x_0; A) = -\ln{\sqrt{2\pi\sigma^2}} - \dfrac{(x_0-A)^2}{2\sigma^2}
$$

一阶导数为

$$
\dfrac{\partial{\ln p(x_0; A)}}{\partial{\theta}} = \dfrac{x_0-A}{\sigma^2}\\
$$

负的二阶导数（对数似然函数的曲率）为

$$
-\dfrac{\partial^2{\ln p(x_0; A)}}{\partial{A}^2} = \dfrac{1}{\sigma^2}\\
$$

随着 $\sigma^2$ 的减少而增加，并且已知 $\mathrm{var}(\hat{A}) = \sigma^2$，则

$$
\mathrm{var}(\hat{A}) = \dfrac{1}{-\dfrac{\partial^2{\ln p(x_0; A)}}{\partial{A}^2}}
$$

更一般的度量是

$$
-E\left [ \dfrac{\partial^2{\ln p(x_0; A)}}{\partial{A}^2} \right]
$$

表示对数自然函数的平均曲率，值越大，表示估计量的方差越小。

> 直观理解：
>
> PDF 的 $x$ 取固定值时，PDF 是参数 A 的（似然）函数，图像越尖锐，估计参数 A 的精度越高。用 **负的二阶导数** 定量描述 **尖锐程度**。
>
> 似然函数的对数曲线对参数越陡，表示数据对该参数越敏感，信息越多，可达的方差下界越小。

### 标量参数的 CRLB

假设对于所有的参数 $\theta$，概率密度函数 $p(\mathbf{x};\theta)$ 满足正则条件

$$
E\left [ \dfrac{\partial{\ln p(x_0;\theta)}}{\partial{\theta}} \right] = 0
$$

那么，任何无偏估计量 $\hat{\theta}$ 的方差满足

$$
\mathrm{var}(\hat{\theta}) \geq \dfrac{1}{-E\left [\dfrac{\partial^2{\ln p(\mathbf{x};\theta)}}{\partial{\theta}^2}\right]}
$$

当且仅当

$$
\dfrac{\partial{\ln p(x_0;\theta)}}{\partial{\theta}} = I(\theta)(g(\mathbf{x}) - \theta)
$$

时，对有所 $\theta$ 达到下限的无偏估计量可以求得，估计量 $\hat{\theta}= g(\mathbf{x})$ 时 MVU 估计量，最小方差是 $\dfrac{1}{I(\theta)}$.

#### 推导过程

左边：

$$
\begin{aligned}
E\left [ \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} \right]
&= \int \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} p(x;\theta) \mathrm{d}x\\
&= \int \dfrac{\partial{p(x;\theta)}}{\partial{\theta}} \mathrm{d}x\\
\end{aligned}
$$

右边：

$$
0 = \dfrac{\partial 1}{\partial \theta} = \dfrac{\partial}{\partial \theta} \int p(x;\theta) \mathrm{d}x
$$

根据牛顿-莱布尼茨公式

$$
\begin{aligned}
F'(t) &= \dfrac{\mathrm{d}}{\mathrm{d}t} \int_{a(t)}^{b(t)} f(x, t) \mathrm{d}x\\
&= f(b(t), t)b'(t) - f(a(t), t) a'(t) + \int_{a(t)}^{b(t)} \dfrac{\partial}{\partial t} f'(x, t) \mathrm{d}x
\end{aligned}
$$

当 **边界随参数变化带来的边界项** $f(b(t), t)b'(t) - f(a(t), t) a'(t)=0$ 时，求积分与求偏导运算可以交换。

假设正则条件满足，两式中的求积分和求偏导运算可以交换，说明 **PDF 的非零边界和参数 $\theta$ 无关**。

---

下面推导标量参数 $\alpha = g(\theta)$ 的 CRLB，对于所有无偏估计量

$$
E(\hat{\alpha}) = \int \hat{\alpha} p(x;\theta)\mathrm{d}x = \alpha = g(\theta)\\
$$

在满足正则条件的前提下，对等式两边求导，得到

$$
\dfrac{\partial g(\theta)}{\partial \theta}
=\dfrac{\partial}{\partial \theta}\int \hat{\alpha} p(x;\theta)\mathrm{d}x
=\int \hat{\alpha} \dfrac{\partial p(x;\theta)}{\partial \theta}\mathrm{d}x
=\int \hat{\alpha} \dfrac{\partial \ln p(x;\theta)}{\partial \theta}p(x;\theta)\mathrm{d}x
$$

根据正则条件 $E\left [ \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} \right] = 0$，可以得到

$$
\int \alpha \dfrac{\partial \ln p(x;\theta)}{\partial \theta}p(x;\theta)\mathrm{d}x
= \alpha E\left [ \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} \right] = 0
$$

两式作差得到

$$
\int (\hat{\alpha} - \alpha) \dfrac{\partial \ln p(x;\theta)}{\partial \theta}p(x;\theta)\mathrm{d}x
= \dfrac{\partial g(\theta)}{\partial \theta}
$$

根据柯西-施瓦茨不等式，

$$
\begin{aligned}
\left( \dfrac{\partial g(\theta)}{\partial \theta} \right)^2 &=
\left( \int (\hat{\alpha} - \alpha) \dfrac{\partial \ln p(x;\theta)}{\partial \theta}p(x;\theta)\mathrm{d}x \right)^2\\
&\leq \int (\hat{\alpha} - \alpha)^2 p(x;\theta)\mathrm{d}x \cdot \int \left(\dfrac{\partial \ln p(x;\theta)}{\partial \theta}\right)^2p(x;\theta)\mathrm{d}x\\
&= \mathrm{var}(\hat{\alpha}) \cdot E\left [ \left(\dfrac{\partial \ln p(x;\theta)}{\partial \theta}\right)^2 \right]\\

\mathrm{var}(\hat{\alpha}) &\geq \dfrac{\left( \dfrac{\partial g(\theta)}{\partial \theta} \right)^2}{E\left [ \left(\dfrac{\partial \ln p(x;\theta)}{\partial \theta}\right)^2 \right]}
\end{aligned}
$$

由正则化条件，

$$
E\left [ \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} \right] = 0
$$

得到

$$
\int \dfrac{\partial \ln p(x;\theta)}{\partial \theta}p(x;\theta)\mathrm{d}x = 0
$$

积分边界与参数 $\theta$ 无关，于是

$$
\begin{aligned}
\dfrac{\partial}{\partial \theta}\int \dfrac{\partial \ln p(x;\theta)}{\partial \theta}p(x;\theta)\mathrm{d}x &= 0\\
\int \left[
\dfrac{\partial^2 \ln p(x;\theta)}{\partial \theta^2}p(x;\theta)
+ \dfrac{\partial \ln p(x;\theta)}{\partial \theta}\dfrac{\partial p(x;\theta)}{\partial \theta}
\right]\mathrm{d}x
&= 0\\
\int \left[
\dfrac{\partial^2 \ln p(x;\theta)}{\partial \theta^2}p(x;\theta)
+ \dfrac{\partial \ln p(x;\theta)}{\partial \theta}\dfrac{\partial \ln p(x;\theta)}{\partial \theta} p(x;\theta)
\right]\mathrm{d}x
&= 0\\
-E\left [ \dfrac{\partial^2 \ln p(x;\theta)}{\partial \theta^2} \right]
&= E\left [ \left(\dfrac{\partial \ln p(x;\theta)}{\partial \theta}\right)^2 \right]\\
\end{aligned}
$$

最终得到，

$$
\mathrm{var}(\hat{\alpha}) \geq \dfrac{\left( \dfrac{\partial g(\theta)}{\partial \theta} \right)^2}{-E\left [ \dfrac{\partial^2 \ln p(x;\theta)}{\partial \theta^2} \right]}
$$

当且仅当无偏估计量 $\hat{\alpha}$ 与对数似然函数的一阶偏导数呈线性关系，即

$$
\dfrac{\partial \ln p(x;\theta)}{\partial \theta} = \dfrac{1}{c}(\hat{\alpha} - \alpha)
$$

时成立，其中 $c$ 与 $x$ 无关。

> 直观理解：
>
> 对数似然函数的一阶偏导数反映“秤”对真实值的敏感程度，取等条件表示估计值和 **敏感程度** 呈固定的比例，“秤”越敏感，估计的误差就按照这个比例调整，几步浪费精度，也不高估“秤”的能力，最终将误差压到最低值。

以 $\alpha = g(\theta) = \theta$ 为例，达到 CRLB 时，

$$
\begin{aligned}
\dfrac{\partial \ln p(x;\theta)}{\partial \theta} &= \dfrac{1}{c(\theta)}(\hat{\theta} - \theta)\\
\dfrac{\partial^2 \ln p(x;\theta)}{\partial \theta^2} &= -\dfrac{1}{c(\theta)} + (\hat{\theta}-\theta)\dfrac{\partial \frac{1}{c(\theta)}}{\partial \theta}\\
-E\left [ \dfrac{\partial^2 \ln p(x;\theta)}{\partial \theta^2} \right] &= \dfrac{1}{c(\theta)}\\
\end{aligned}
$$

定义 Fisher 信息 $I(\theta) = -E\left [ \dfrac{\partial^2 \ln p(x;\theta)}{\partial \theta^2} \right]$，则

$$
c(\theta) = \dfrac{1}{I(\theta)}
$$

### 矢量参数的 CRLB

现将前一部分的结果扩展到估计矢量参数 $\boldsymbol{\theta}=[\theta_1 \theta_2\cdots \theta_p]^{\top}$，假定 $\hat{\boldsymbol{\theta}}$ 是无偏估计，矢量参数的 CRLB 允许对每隔元素的方差放置一个下限，即

$$
\mathrm{var}(\hat{\theta_i}) \geq [\mathbf{I}^{-1}(\boldsymbol{\theta})]_{ii}
$$

其中 $\mathbf{I}(\boldsymbol{\theta})$ 是 $p\times p$ 的 Fisher 信息矩阵，

$$
[\mathbf{I}(\boldsymbol{\theta})]_{ij} = -E\left [ \dfrac{\partial^2 \ln p(\mathbf{x};\boldsymbol{\theta})}{\partial \theta_i\partial \theta_j} \right]\quad i = 1,2,\cdots, p; j = 1,2,\cdots, p\\
$$

假设 PDF $p(\mathbf{x};\boldsymbol{\theta})$ 满足正则条件

$$
E\left [ \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} \right] = 0
$$

则任何无偏估计量 $\hat{\boldsymbol{\theta}}$ 的协方差矩阵满足

$$
\mathbf{C}_{\hat{\boldsymbol{\theta}}} \geq \mathbf{I}^{-1}(\hat{\boldsymbol{\theta}})
$$

当且仅当

$$
[\mathbf{I}(\boldsymbol{\theta})]_{ij} = \mathbf{I}(\boldsymbol{\theta})(\mathbf{g}(x)-\boldsymbol{\theta})
$$

时可达下限。

#### 推导过程


下面推导矢量参数 $\boldsymbol{\alpha} = \mathbf{g}(\boldsymbol{\theta})$ 的 CRLB，考虑无偏估计量

$$
E(\hat{\alpha_i}) = \alpha_i = [\mathbf{g}(\boldsymbol{\theta})]_i \quad i = 1,2,\cdots, r
$$

根据正则条件 $E\left [ \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} \right] = 0$，可以得到

$$
\int \alpha \dfrac{\partial \ln p(x;\theta)}{\partial \theta}p(x;\theta)\mathrm{d}x
= \alpha E\left [ \dfrac{\partial{\ln p(x;\theta)}}{\partial{\theta}} \right] = 0
$$

两式作差得到

$$
\int (\hat{\alpha}_i - \alpha_i) \dfrac{\partial \ln p(x;\theta)}{\partial \theta_i}p(x;\theta)\mathrm{d}x
= \dfrac{\partial [g(\theta)]_i}{\partial \theta_i}
$$

当 $i\not= j$ 时，

$$
\begin{aligned}
\int (\hat{\alpha}_i - \alpha_i) \dfrac{\partial \ln p(x;\theta)}{\partial \theta_j}p(x;\theta)\mathrm{d}x
&= \int (\hat{\alpha}_i - \alpha_i) \dfrac{\partial  p(x;\theta)}{\partial \theta_j}\mathrm{d}x\\
&= \dfrac{\partial}{\partial \theta_j}\int \hat{\alpha}_i p(x;\theta)\mathrm{d}x
- \alpha_iE\left [ \dfrac{\partial\ln p(x;\theta)}{\partial \theta_j} \right]\\
&= \dfrac{\partial \alpha_i}{\partial \theta_j}\\
&= \dfrac{\partial [g(\theta)]_i}{\partial \theta_j}\\
\end{aligned}
$$

组合成矩阵形式


$$
\int (\hat{\boldsymbol{\alpha}} - \boldsymbol{\alpha}) \dfrac{\partial \ln p(\mathbf{x};\boldsymbol{\theta})^{\top}}{\partial \theta_j}p(\mathbf{x};\boldsymbol{\theta})\mathrm{d}x = \dfrac{\partial [\mathbf{g}(\boldsymbol{\theta})]}{\partial \boldsymbol{\theta}}\\
$$

对于任意的 $t\times 1$ 矢量 $\mathbf{a}$ 和 $p\times 1$ 矢量 $\mathbf{b}$，

$$
\int \mathbf{a}^{\top}(\hat{\boldsymbol{\alpha}} - \boldsymbol{\alpha}) \dfrac{\partial \ln p(\mathbf{x};\boldsymbol{\theta})^{\top}}{\partial \theta_j} \mathbf{b} p(\mathbf{x};\boldsymbol{\theta})\mathrm{d}x = \mathbf{a}^{\top}\dfrac{\partial [\mathbf{g}(\boldsymbol{\theta})]}{\partial \boldsymbol{\theta}}\mathbf{b} \\
$$

由柯西-施瓦茨不等式

$$
\begin{aligned}
\mathbf{a}^{\top}\dfrac{\partial [\mathbf{g}(\boldsymbol{\theta})]}{\partial \boldsymbol{\theta}}\mathbf{b}
&\leq
\int \mathbf{a}^{\top}(\hat{\boldsymbol{\alpha}} - \boldsymbol{\alpha})(\hat{\boldsymbol{\alpha}} - \boldsymbol{\alpha})^{\top}\mathbf{a}p(\mathbf{x};\boldsymbol{\theta})\mathrm{d}x \cdot
\int \mathbf{b}^{\top} \dfrac{\partial \ln p(\mathbf{x};\boldsymbol{\theta})}{\partial \theta_j}\dfrac{\partial \ln p(\mathbf{x};\boldsymbol{\theta})^{\top}}{\partial \theta_j} \mathbf{b} p(\mathbf{x};\boldsymbol{\theta})\mathrm{d}x\\
&= \mathbf{a}^{\top} C_{\hat{\alpha}} \mathbf{a} \mathbf{b}^T I(\boldsymbol{\theta}) \mathbf{b}\\
\end{aligned}
$$

并且

$$
E\left [ \frac{\partial \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \theta_i} \frac{\partial \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \theta_j} \right] = -E\left [ \frac{\partial^2 \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \theta_i \partial \theta_j} \right] = [\mathbf{I}(\boldsymbol{\theta})]_{ij}
$$

令

$$
\mathbf{b} = \mathbf{I}^{-1}(\boldsymbol{\theta}) \frac{\partial \mathbf{g}(\boldsymbol{\theta})^T}{\partial \boldsymbol{\theta}} \mathbf{a}
$$

进一步得到

$$
\left( \mathbf{a}^T \frac{\partial \mathbf{g}(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \mathbf{I}^{-1}(\boldsymbol{\theta}) \frac{\partial \mathbf{g}(\boldsymbol{\theta})^T}{\partial \boldsymbol{\theta}} \mathbf{a} \right)^2 \leqslant \mathbf{a}^T \mathbf{C}_{\hat{\alpha}} \mathbf{a} \left( \mathbf{a}^T \frac{\partial \mathbf{g}(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \mathbf{I}^{-1}(\boldsymbol{\theta}) \frac{\partial \mathbf{g}(\boldsymbol{\theta})^T}{\partial \boldsymbol{\theta}} \mathbf{a} \right)
$$

由于 $\mathbf{I}(\boldsymbol{\theta})$ 正定，得到

$$
\mathbf{a}^T \left( \mathbf{C}_{\hat{\alpha}} - \frac{\partial \mathbf{g}(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \mathbf{I}^{-1}(\boldsymbol{\theta}) \frac{\partial \mathbf{g}(\boldsymbol{\theta})^T}{\partial \boldsymbol{\theta}} \right) \mathbf{a} \geqslant 0
$$

$$
\mathbf{a}^T (\hat{\alpha} - \alpha) = c \frac{\partial \ln p(\mathbf{x}; \boldsymbol{\theta})^T}{\partial \boldsymbol{\theta}} \mathbf{b} = c \frac{\partial \ln p(\mathbf{x}; \boldsymbol{\theta})^T}{\partial \boldsymbol{\theta}} \mathbf{I}^{-1}(\boldsymbol{\theta}) \frac{\partial \mathbf{g}(\boldsymbol{\theta})^T}{\partial \boldsymbol{\theta}} \mathbf{a}
$$

取等条件为

$$
\frac{\partial \mathbf{g}(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \mathbf{I}^{-1}(\boldsymbol{\theta}) \frac{\partial \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \boldsymbol{\theta}} = \frac{1}{c} (\hat{\alpha} - \alpha)
$$

与上一部分推导标量的类似，考虑 $\boldsymbol{\alpha} = \mathbf{g}(\boldsymbol{\theta}) = \boldsymbol{\theta}$ 时，$\dfrac{\partial \mathbf{g}(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} = \mathbf{I}$

$$
\frac{\partial \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \boldsymbol{\theta}} = \frac{1}{c} \mathbf{I}(\boldsymbol{\theta}) (\hat{\boldsymbol{\theta}} - \boldsymbol{\theta})
$$

$$
\begin{aligned}
\frac{\partial \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \theta_i} &= \sum_{k = 1}^p \frac{[\mathbf{I}(\boldsymbol{\theta})]_{ik}}{c(\boldsymbol{\theta})} (\hat{\theta}_k - \theta_k)\\

\frac{\partial^2 \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \theta_i \partial \theta_j} &= \sum_{k = 1}^p \left( \frac{[\mathbf{I}(\boldsymbol{\theta})] _{ik}}{c(\boldsymbol{\theta})} (-\delta_{kj}) + \frac{\partial \left( \dfrac{[\mathbf{I}(\boldsymbol{\theta})]_{ik}}{c(\boldsymbol{\theta})} \right)}{\partial \theta_j} (\hat{\theta}_k - \theta_k) \right)、、
\end{aligned}
$$

$$
[\mathbf{I}(\boldsymbol{\theta})] _{ij} = -E\left [ \frac{\partial^2 \ln p(\mathbf{x}; \boldsymbol{\theta})}{\partial \theta_i \partial \theta_j} \right] = \frac{[\mathbf{I}(\boldsymbol{\theta})]_{ij}}{c(\boldsymbol{\theta})}
$$
