---
title: 广义线性模型
tags:
  - 线性回归
  - 逻辑回归
categories: 人工智能
mathjax: true
abbrlink: 59c3166
date: 2025-12-04 17:12:44
---

在回归模型中，线性回归表示为 $y=\theta^{\top}x$，逻辑回归表示为 $y=\dfrac{1}{1+e^{-\theta^{\top}x}}$……为了使这形式不同的回归模型得到统一，引入了广义线性模型（GLM）

## GLM 的定义

GLM 基于三项定义：

- 线性预测算子：$\eta = \theta^{\top}x$
- 链接函数：将响应变量的期望与线性预测算子联系，定义为 $g(\mu)=\eta$，其中 $\eta = \theta^{\top} x, \mu=\mathbb{E}(y|x)$

函数的输入域是分布允许的范围，例如 Bernoulli 分布的期望 $\mu\in(0,1)$；函数的输出是线性预测器，数值范围通常是整个实数域

- 响应变量服从指数族分布 $\Pr(y|x,\theta) = b(y)\exp(\eta^{\top}T(y) - a(\eta))$，如二项分布、泊松分布、正态分布

### 线性预测算子

$$
\eta = \theta^{\top}x = \theta_n x_x + \theta_{n-1}x_{n-1} + \cdots \theta_1 x_1 + \theta_0 x_0\\
$$

其中 $x_0 = 1$.

### 期望估计

将回归理解为求条件分布 $\Pr(y|x,\theta)$ 的过程，得到分布后，用期望作为预测值 $h(x,\theta)=\mathbb{E}(y|x,\theta)$，用方差作为预测值的不确定性。

### 指数分布族

$$
\Pr(y|x,\theta) = b(y)\exp(\eta^{\top}T(y) - a(\eta))
$$

注：$e^{-a(\eta)}$ 起着归一化常数的作用，确保 $\Pr(y|x,\theta)$ 在 $y$ 上的积分为 1.

---

以高斯分布为例，为了简化推导，令 $\sigma^2=1$，则有

$$
\begin{aligned}
\Pr(y; mu) &= \dfrac{1}{\sqrt{2\pi}} \exp\left( -\dfrac{1}{2}(y-\mu)^2 \right)\\
&= \dfrac{1}{\sqrt{2\pi}} \exp\left( -\dfrac{1}{2}y^2 + \mu y - \dfrac{1}{2}\mu^2 \right)\\
&= \dfrac{1}{\sqrt{2\pi}} \exp\left( -\dfrac{1}{2}y^2 \right) \cdot \exp\left(\mu y - \dfrac{1}{2}\mu^2 \right)\\
\end{aligned}
$$

则

$$
\begin{aligned}
b(y) &= \dfrac{1}{\sqrt{2\pi}} \exp\left( -\dfrac{1}{2}y^2 \right)\\
\eta &= \mu\\
T(y) &= y\\
a(\eta) &= \dfrac{1}{2}\mu^2 =\dfrac{1}{2}\eta^2 \\
\end{aligned}
$$

---

以 Bernoulli 分布为例，将均值为 $\mu$ 的 Bernoulli 分布记作 $\mathrm{Bernoulli}(\mu)$，使得 $\Pr(y=1|\mu) = \mu, \space \Pr(y=0|\mu)=1-\mu$，现将 Bernoulli 分布写成

$$
\begin{aligned}
\Pr(y;\mu) &= \mu^y(1-\mu)^{1-y}\\
&= \exp(y\log \mu + (1-y)\log(1-\mu))\\
&= \exp(y \log \left(\dfrac{\mu}{1-\mu}\right) + \log(1-\mu))\\
\end{aligned}
$$

则 $\eta =  \log \left(\dfrac{\mu}{1-\mu}\right)$，求逆函数可以得到 $\mu = \dfrac{1}{1 + e^{-\eta}}$，其余项

$$
\begin{aligned}
T(y) &= y\\
a(\eta) &= -\log(1-\mu)=\log(1+e^{\eta})\\
b(y) &= 1
\end{aligned}
$$

## 典型模型

### 线性回归

- 响应变量的分布：$y \sim \mathcal{N}(\mu,\sigma^2)$
- 链接函数：$g(\mu) = \mu$

- 预测：$\mu = \theta^{\top}x$

### 逻辑回归

- 响应变量的分布：$y \sim \mathrm{Bernoulli}(\mu)$
- 链接函数：$g(\mu) = \log\left( \dfrac{\mu}{1-\mu} \right)$

$$
\log\left( \dfrac{\mu}{1-\mu} \right) = \theta^{\top}x
$$

对应的 $\mu = g^{-1}(\theta^{\top}x) = \dfrac{1}{1 + e^{-\theta^{\top}x}}$

- 预测：$\mu = \dfrac{1}{1 + \exp{(-\theta^{\top}x)}}$

### 泊松回归

- 响应变量的分布：$y\sim \mathrm{Poisson}(\mu)$
- 链接函数：$g(\mu)=\log(\mu)$
- 预测：$\mu = \exp(\theta^{\top}x)$

## 参考资料

[cycleuser/Stanford-CS-229](https://github.com/cycleuser/Stanford-CS-229)

[广义线性模型 学习笔记（一）——定义](https://xg1990.com/blog/archives/304)
